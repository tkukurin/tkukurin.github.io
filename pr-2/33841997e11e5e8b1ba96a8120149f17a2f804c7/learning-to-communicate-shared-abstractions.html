<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    <title>Learning to communicate about shared procedural abstractions</title>
    <meta name="description" content="Learning to communicate about shared procedural abstractions seems like another confirmation of learning being a form of compression. Leans on Convention for...">
    <link rel="canonical" href="https://tkukurin.github.io/learning-to-communicate-shared-abstractions">
  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/light.css">
  <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  learning-to-communicate-about-shared-procedural-abstractions">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">~</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">caveat emptor</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <div class="page-sidebar">
        
            
            <h1 id="page-title" class="page-title p-name">Learning to communicate about shared procedural abstractions
</h1>
        
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2021-06-27T00:00:00+00:00"><a class="u-url" href="">Jun 27, 2021</a>
</time>

  </div>
</div>

        

        
  <h3 class="page-taxonomies-title">Tags</h3>
  <ul class="page-taxonomies"><li class="page-taxonomy">cogsci</li><li class="page-taxonomy">research</li>
  </ul>


      </div>

      <div class="page-content">
        <div class="e-content">
          <p><a href="https://rxdhawkins.files.wordpress.com/2021/05/caml_cogsci-1.pdf">Learning to communicate about shared procedural abstractions</a>
seems like another confirmation of learning being a form of compression.
Leans on <a href="https://cogsci.mindmodeling.org/2017/papers/0098/paper0098.pdf">Convention formation in iterated reference games</a>.
Humans use more efficient contextualized language to chunk useful concepts.
<a href="https://github.com/cogtoolslab/compositional-abstractions">GitHub repo</a>.</p>

<h2 id="setup">Setup</h2>

<p>98 humans paired up for a collaborative assembly task in 12 trials.
Given a target scene <em>architect</em> instructs (up to 100 chars/turn) <em>builder</em> how
to create that scene from some basic building blocks.
Each scene consist of two towers (repeated across experiments); each tower of 4
dominoes. Tower types: (1) an arch, (2) “C”-shaped, and (3) “L”-shaped.
After each trial, both participants see feedback about scene mismatch.</p>

<p><img src="/assets/img/2021-06-27-shared-abstractions-fig1.png" alt="Figure 1" /></p>

<h2 id="eval">Eval</h2>

<p>Start and final word distributions compared using permutation-based \(\chi^2\).
As trials progressed, words like “block” and “horizontal” were used less
frequently, while “C” and “shape” more frequently.</p>

<p><a href="https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-linear-mixed-models/">Linear Mixed Effects</a>
(x = repetition number) models show gain in efficiency.</p>

<p>Comparison between (architect, builder) pairs using Jensen-Shannon divergence
(JSD) within each repetition.
<strong>Interestingly</strong> JSD between pairs <em>increases</em> with trial number; i.e. a
diverse language emerges even in this simple domain.</p>

<h2 id="computational-model">Computational model</h2>

<blockquote>
  <p>The Architect must (1) have an underlying representation of the procedure they
intend to communicate, (2) maintain uncertainty about whether the Builder is
likely to share that representation, and (3) prefer shorter message over
longer messages, all else being equal […] as the Architect becomes more
confident that their abstracted referring expressions will be interpreted
correctly, they increasingly prefer more efficient descriptions.</p>
</blockquote>

<h3 id="bayesian-program-learning">Bayesian program learning</h3>

<p>Each agent maintains a library of primitives \(L\) to be combined; initialized
with: \(h\) (horizontal), \(v\) (vertical), \(l\) (move left), \(r\) (move
right) and digits \(1-9\).
Trials of tower scenes designated \(\{T_n\}_1^N\).
The model proposes a set of candidate sub-routine fragments \(f\) after each
trial and updates a posterior over possible ways of extending the library:</p>

\[P(L \cup \{f\} | \{T_n\}_1^N) \propto
  \underbrace{P(L \cup \{f\})}_{\textrm{description-length prior}}
  \cdot
  \underbrace{\prod_{n=1}^N P(T_n|L \cup \{f\})}_{\textrm{likelihood}}\]

<p>The likelihood captures the ability of an extended library efficiently to
explain previous towers:</p>

\[P(T_n | L \cup \{f\}) =
  \exp \left \{ -\textrm{MDL}(T_n | L \cup \{f\}) \right \}\]

<p>The prior captures a preference for smaller libraries:</p>

\[P(L\cup \{f\}) = \exp \left\{ -w \cdot \textrm{size}(L \cup \{f\}) \right\}\]

<h3 id="communication-as-social-reasoning">Communication as social reasoning</h3>

<p>Following recent work, they model emergent language according to social utility.
E.g. <a href="http://www.cogsci.bme.hu/~ktkuser/KURZUSOK/BMETE47MC15/2019_2020_1/Cikkek/GoodmanFrank2016.pdf">Pragmatic Language Interpretation as Probabilistic Inference</a>:</p>
<blockquote>
  <p>Building on developments in game theory and probabilistic modeling, we
describe the rational speech act (RSA) framework for pragmatic reasoning. RSA
models provide a principled way to formalize inferences about meaning in
context; they have been used to make successful quantitative predictions about
human behavior in a variety of different tasks and situations, and they
explain why complex phenomena, such as hyperbole and vagueness, occur. More
generally, they provide a computational framework for integrating linguistic
structure, world knowledge, and context in pragmatic language understanding.</p>
</blockquote>

<p>Utterance step \(t_i\), procedural sequence \(T\).</p>

\[P_s(u|t_i)  \propto \exp\{-\alpha U(u;t_i)\}\]

\[U(u;t_i) = \log P_l(t_i|u)\]

\[P_L(t_i|u) \propto \delta_{u}(t_i)\]

<p>Delta is the literal meaning function that the Builder is expected to use.
Architect can represent the raw scene \(T*\) using multiple programs \(T^k\):</p>

\[U(u, T^k; T*) =
  \left ( (1-\beta) \sum \ln P_L(t_i^k | u) \right )
  - \left ( \beta \cdot |T^k| \right )\]

<p>Where β is a parameter controlling the architect’s cost sensitivity, i.e. how
much weight do they put on description length.
The Builder may not know Architect’s language, so the Architects maintains an
additional prior \(P([[ u ]])\) of the builder agent’s lexicon \([[u]]\),
cf. <a href="https://arxiv.org/pdf/1903.08237.pdf">When redundancy is useful</a>:</p>
<blockquote>
  <p>Rational theories of language use have come under attack [for failing to]
account for the seemingly irrational overinformativeness of referring
expressions. [We present a model] that treats speakers as agents that
rationally trade off cost and informativeness of utterances.</p>
</blockquote>

<p>Not clear what “roughly” means in:</p>
<blockquote>
  <p>intermediate values of β roughly reproduced the qualitative Architect behavior</p>
</blockquote>

<h2 id="discussion">Discussion</h2>

<p>Future work</p>
<ul>
  <li>Investigate sources of consistency and variability
    <ul>
      <li>e.g. “C-shape”, “upside-down U”</li>
    </ul>
  </li>
  <li>Investigate within-pair references to previous trials</li>
  <li>Refine learning algorithm to fit experimental results</li>
  <li>Collect realistic priors</li>
  <li>Investigate tasks where participants learn at different rates</li>
</ul>

<p>They are currently implementing a SOTA Bayesian program learning algorithm that
incorporates language into the learning procedure.</p>


        </div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/learning-salon-recap-2021">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Learning Salon: Recap &amp; Discussion

      </span>
    </a>
  

  
    <a class="page-next" href="/prompt-tuning">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Simple Few-Shot Learning with Language Models
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>

    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://twitter.com/tkukurin"><i class="fab fa-twitter-square fa-2x" title="Twitter"></i></a><a class="social-icon" href="https://github.com/tkukurin"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/toni/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      

    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>

</html>
