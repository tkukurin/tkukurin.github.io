<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    <title>Reward is enough</title>
    <meta name="description" content="Quick notes on Reward is enough. I wasn’t aware this paper was supposed to be controversial, but it sparked quite a lively debate on Learning Salon. To me th...">
    <link rel="canonical" href="https://tkukurin.github.io/reward-is-enough">
  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/light.css">
  <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  reward-is-enough">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">~</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">caveat emptor</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <div class="page-sidebar">
        
            
            <h1 id="page-title" class="page-title p-name">Reward is enough
</h1>
        
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2021-06-20T00:00:00+00:00"><a class="u-url" href="">Jun 20, 2021</a>
</time>

  </div>
</div>

        

        
  <h3 class="page-taxonomies-title">Tags</h3>
  <ul class="page-taxonomies"><li class="page-taxonomy">research</li><li class="page-taxonomy">rl</li>
  </ul>


      </div>

      <div class="page-content">
        <div class="e-content">
          <p>Quick notes on <a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862">Reward is enough</a>.
I wasn’t aware this paper was supposed to be controversial, but it sparked quite
a lively debate on Learning Salon.
To me the the paper makes perfect sense. Argues that general intelligence arises
in complex environments, even from seemingly innocuous signals.
Wasn’t some version of this written by Skinner in the mid-1900s?
Aren’t economists usually writing these types of papers, substituting
intelligence for some other behavior that’s supposed to emerge from a model?</p>

<p>Anyhow. My <strong>TL;DR</strong>: intelligence is emergent behavior facilitated by any kind
of reward present in a complex environment.
Titled “Reward is Enough” for likely PR reasons, actually argues to say reward
is a necessary but insufficient condition.</p>

<blockquote>
  <p>The behaviour of the squirrel may be understood as maximising a cumulative
reward such as satiation (i.e. negative hunger). In order for a squirrel to
minimise hunger, the squirrel-brain must presumably have abilities of
perception (to identify good nuts), knowledge (to understand nuts), motor
control (to collect nuts), planning (to choose where to cache nuts), memory
(to recall locations of cached nuts) and social intelligence (to bluff about
locations of cached nuts, to ensure they are not stolen).</p>
</blockquote>

<p>Well yeah, these behaviors seem distinct because they named them as such.
If I granulate on a “nut-usefulness” level then perception, knowledge, planning,
memory and social intelligence can all be a single ability.</p>

<p>Knowledge: information that is <em>internal</em> to the agent.
May be learned or innate; long-lived environments favor the former.</p>

<blockquote>
  <p>innate understanding of predator evasion may be necessary before there is any
opportunity to learn this knowledge. Note, however, that the extent of prior
knowledge is limited both in theory (by the capacity of the agent) and in
practice (by the difficulty of constructing useful prior knowledge).</p>
</blockquote>

<p><em>Perception</em> could be subserving e.g. maximization of healthy food, avoiding
accidents, minimizing pain.
<em>Social intelligence</em> could arise just from the presence of other agents.
They kind of relate <em>language</em> to social intelligence, saying it arises from an
agent’s need to communicate its complex environment to achieve goals.</p>

<p>I guess a simplified view of the perception hierarchy goes something like:</p>
<ul>
  <li>Survival
    <ul>
      <li>Energy
        <ul>
          <li>Food acquisition
            <ul>
              <li>Discern edible items
                <ul>
                  <li>Perception</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Minimize pain
            <ul>
              <li>Avoid hurtful situations (e.g. falling off a cliff)
                <ul>
                  <li>Perception</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Then some not-too-convincing lamentation about <em>generalization</em> being useful for
maximizing an agent’s understanding within a rich environment.
I would’ve claimed that an agent perhaps has limited cognitive capacity, and as
such generalization is a consequence of interference but what do I know.
Maybe I don’t get what they’re trying to say.</p>

<blockquote>
  <p>We do not offer any theoretical guarantee on the sample efficiency of
reinforcement learning agents. Indeed, the rate at and degree to which
abilities emerge will depend upon the speciﬁc environment, learning algorithm,
and inductive biases.</p>
</blockquote>

<hr />

<p><em>Which environment?</em> Depends on what you’re trying to achieve.
But it doesn’t matter, because the real question is… <em>Which reward signal?</em>
The desire to manipulate the reward signal often arises from the idea that only
a <em>carefully constructed reward</em> could induce general intelligence.
This paper suggests that, the more complex the environment, the more complex the
behavior, irrespective of reward (e.g. pebble collecting).</p>

<p>In their framework, reproductive success is e.g. a possible reward that drives
the emergence of intelligence.
Reinforcement learning is the best choice, because:</p>
<ul>
  <li>unsupervised learning and prediction lack action selection</li>
  <li>supervised learning is a shortcut that can teach a subset of what humans know</li>
  <li>maximization of free energy or minimization of surprise can’t be directed to
achieve specific goals across different environments</li>
</ul>

<p>As such, they argue against offline RL (no feedback to direct the agent towards
their particular goals).</p>

<p><em>Is the reward signal too impoverished?</em> I think they agree with me on this one,
the single learning signal will actually lead to the emergence of “sub-signals”
(e.g. survival necessitates food acquisition) which the agent will learn:</p>
<blockquote>
  <p>Many solution methods, including model-free reinforcement learning, learn to
associate future reward with features of observations, through value function
approximation, which in turn provide rich secondary signals that drive
learning of deeper associations through a recursive bootstrapping process.</p>
</blockquote>

<hr />

<p>Lest I forget:
there is no distinction being made between “useful” and “intelligent”.</p>

<p>Asking a self-driving car to bring you closer to a specific location, even in
the presence of a perfectly complex environment, may lead to both intelligent
and “wrong” behavior, failing to deliver on the promise of AI.</p>

<p>But I guess the same is true with humans, so eh.
I’m sure Yudkowski would have some comments there.</p>

<p><em>Some kind of summary</em>:
Under the “reward is enough” framework, every intelligent agent is wired to
follow a simple reward but the behavior that emerges is largely influenced by
priors (“model weights”) and environment interactions (“gradient descent”).
Thus it’s just shifting the burdern of explaining intelligence towards other
parts of the system.</p>


        </div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/apperception-code">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Making Sense of Sensory Input; Apperception code

      </span>
    </a>
  

  
    <a class="page-next" href="/learning-salon-recap-2021">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Learning Salon: Recap &amp; Discussion
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>

    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://twitter.com/tkukurin"><i class="fab fa-twitter-square fa-2x" title="Twitter"></i></a><a class="social-icon" href="https://github.com/tkukurin"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/toni/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      

    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>

</html>
