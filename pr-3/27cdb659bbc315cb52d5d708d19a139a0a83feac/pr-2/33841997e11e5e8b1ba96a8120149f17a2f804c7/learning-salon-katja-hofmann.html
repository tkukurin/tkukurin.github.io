<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    <title>Learning Salon: Katja Hofmann, Deep RL for Games</title>
    <meta name="description" content="Very quick notes from Katja’s Learning Salon talk on Deep RL for Games at MS Cambridge.">
    <link rel="canonical" href="https://tkukurin.github.io/learning-salon-katja-hofmann">
  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/light.css">
  <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  learning-salon-katja-hofmann-deep-rl-for-games">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">~</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">caveat emptor</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <div class="page-sidebar">
        
            
            <h1 id="page-title" class="page-title p-name">Learning Salon: Katja Hofmann, Deep RL for Games
</h1>
        
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2021-02-27T00:00:00+00:00"><a class="u-url" href="">Feb 27, 2021</a>
</time>

  </div>
</div>

        

        
  <h3 class="page-taxonomies-title">Tags</h3>
  <ul class="page-taxonomies"><li class="page-taxonomy">neuro</li><li class="page-taxonomy">rl</li>
  </ul>


      </div>

      <div class="page-content">
        <div class="e-content">
          <p>Very quick notes from <a href="https://www.youtube.com/watch?v=MFyjE6_kTvE">Katja’s Learning Salon talk</a>
on Deep RL for Games at MS Cambridge.</p>

<h2 id="links">Links</h2>

<ul>
  <li><a href="https://www.microsoft.com/en-us/research/project/project-malmo/">Project Malmo: Minecraft for AI experimentation</a> (<a href="https://github.com/microsoft/malmo">GitHub</a>)
    <ul>
      <li><a href="minerl.io/competition">MineRL</a> focus on sample-efficient usage of human
demonstrations</li>
    </ul>
  </li>
  <li><a href="https://openreview.net/pdf?id=Bkl7bREtDr">AMRL: Aggregated Memory for RL</a>;
goal: navigate a long maze; modification to “standard” RL LSTM adding a memory
cell (kind of like Manning’s work on MAC cells?)
    <ul>
      <li>simulating noise: add a single randomly sampled variable as input;
only LSTM is not very robust</li>
      <li>memory is a running average of all hidden states so far</li>
      <li>subtasks are kind of “pseudo-noise” (short-term dependencies)</li>
    </ul>
  </li>
  <li><a href="https://innovation.microsoft.com/en-us/exploring-project-paidia">Project Paidia</a>:
agents that adapt on the spot to new teammates and opponents. <a href="https://youtu.be/MFyjE6_kTvE?t=1133">YT</a></li>
  <li>Deep Interactive Bayesian RL via Meta-Learning <a href="https://youtu.be/MFyjE6_kTvE?t=1388">YT</a></li>
  <li>MeLIBA <a href="https://youtu.be/MFyjE6_kTvE?t=1493">YT</a> - is it useful to explicitly
model other agent’s actions to maximize some notion of “global” reward (e.g.
take all coins to appropriate banks)
    <ul>
      <li>VAE to model other agent’s state</li>
    </ul>
  </li>
  <li><a href="https://www.microsoft.com/en-us/research/event/aiandgaming2021/">AI and gaming research summit at Microsoft</a>
talks should soon be available online.</li>
</ul>

<h2 id="discussion">Discussion</h2>

<p>Are games “just something that conforms to RL algorithms?”
No.  But in games, human players and AI are at similar footing.</p>

<p>What is an “RL agent”?
Whatever we can <em>model</em>.
[Yes, pretty sure that’s exactly what Sutton&amp;Barto mention in their book.]
John: we can’t ascribe “agency” to the weather. [Can’t we?]</p>

<p>Why games? Combination of motivation, control and flexibility.
Easy to collect data, can be setup in a multitude of ways.
Virtual environments can be made “safe” [assuming transfer to real world works].</p>

<p>Games where you can’t define a goal beforehand?
Curiosity-driven exploration, automated curriculum learning, etc.
Katja is hopeful on meta-learning.</p>

<p>Katja: it makes sense to assume you can define anything as a “reward”, but the
rewards themselves are varied (e.g. humans can learn based off of “well done”).</p>

<p>[NOTE: a lot of the things they are discussing seem to be rehashed from
Minsky’s <a href="https://amzn.to/2ZWQpzC">Society of Mind</a>.]</p>

<p>Learning to be a good opponent seems to be easier than learning to be a good
teammate.
[Makes sense, it’s easier to define the inverse optimization function.]
Maybe make mistakes on purpose and then force other agent to compensate?</p>

<p>How about free play mode?
Katja didn’t make experiments there yet.
Some ideas on how to <em>force</em> agents to find their own goals: social environment.
John: “Everything is a version of something before it”
[Well yes, the world is compositional, <em>only physics is true</em>.]</p>

<p>Darwin: don’t conflate story about how you got to X vs. how X works.
E.g. there is a story on how you evolved a brain, not how it works.</p>

<p>Jovo: There is no objective in evolution.
[Not sure about that. Isn’t human learning just optimizing for survival given
some “natural” inductive biases?]</p>

<p>John: Our learning not completely different from animals, more like “average
animal + something else”.
Brad: boredom as creativity signal [Again something Minsky discusses].</p>

<p>Zenna asked something like “is creativity an emergent property of RL-model-based
optimization” (?) [I think so, but eehhhh.]</p>

<p>John: Games are a bit more like an engineering problem, vs.  philosophical
questions. “Why is there a river here?” vs. “How do I build a bridge over this
river?”
[I think John is actually hinting at intrinsic motivation and meta-learning. We
<em>are</em> actually trying to model these questions with RL.]
There’s no reason to be optimistic about it without any concrete proof, and it
seems that <a href="https://youtu.be/MFyjE6_kTvE?t=7782">we don’t have proof right now.</a></p>

<p>David: The agents are quite passive.</p>

<p>Have you modeled something like <em>joy</em> in the agents?
Nope; what does joy mean for a human player?</p>

<p><img src="https://image.flaticon.com/icons/png/512/826/826963.png" alt="Penguins are fun" width="75px" /></p>


        </div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/bert-variants">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> BERT objectives

      </span>
    </a>
  

  
    <a class="page-next" href="/semantic-grounding-novel-spoken-words">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Semantic Grounding of Novel Spoken Words in the Primary Visual Cortex
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>

    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://twitter.com/tkukurin"><i class="fab fa-twitter-square fa-2x" title="Twitter"></i></a><a class="social-icon" href="https://github.com/tkukurin"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/toni/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      

    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>

</html>
