<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    <title>If Deep Learning is the answer, what is the question?</title>
    <meta name="description" content="By Andrew Saxe, Stephanie Nelli, Christopher Summerfield. How can neuroscientists use DL to understand biological brains? What are conceptual &amp;amp; methodolo...">
    <link rel="canonical" href="https://tkukurin.github.io/if-dl-is-the-answer">
  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/light.css">
  <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  if-deep-learning-is-the-answer-what-is-the-question">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">~</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">caveat emptor</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <div class="page-sidebar">
        
            
            <h1 id="page-title" class="page-title p-name">If Deep Learning is the answer, what is the question?
</h1>
        
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2020-11-24T00:00:00+00:00"><a class="u-url" href="">Nov 24, 2020</a>
</time>

  </div>
</div>

        

        
  <h3 class="page-taxonomies-title">Tags</h3>
  <ul class="page-taxonomies"><li class="page-taxonomy">neuro</li><li class="page-taxonomy">research</li>
  </ul>


      </div>

      <div class="page-content">
        <div class="e-content">
          <p>By <a href="https://arxiv.org/pdf/2004.07580.pdf">Andrew Saxe, Stephanie Nelli, Christopher Summerfield</a>.
How can neuroscientists use DL to understand biological brains?
What are conceptual &amp; methodological challenges of comparing behaviour, learning
dynamics, and neural representation in artificial and biological systems?
Resurgence of 1980s PDP ideas: current compute can learn from raw data,
as opposed to hand-extracted features.</p>

<h2 id="limitations-of-the-dl-framework">Limitations of the DL framework</h2>

<blockquote>
  <p>If neural computation emerges uncontrollably through blind, unconstrained
optimisation, then how can neuroscientists formulate new, empirically testable
hypotheses about neural mechanism? Such hypotheses are argued to take the form
of design choices about learning rules, regularisation principles, or
architectural constraints in deep networks.</p>
</blockquote>

<p>Comparing neural and deep representations is statistically challegning.
A popular approach is to learn a linear mapping from neurons to network units,
and to evaluate the predictive validity on a held-out dataset.
DNNs can explain 60% of variance, but DNNs that don’t classify images correctly
can explain 55%.</p>

<p>With RSA, it’s unclear what type of agreement is being tested.</p>

<h2 id="structure-in-animal-learning">Structure in animal learning</h2>

<blockquote>
  <p>Animal behaviour is richly structured, in theory permitting researchers to
make systematic comparisons with machine performance. E.g., animal decisions
are subject to stereotyped biases, but also irreducibly noisy; animals are
<strong>flexible but forgetful</strong>, behaving as if memory and control systems were
capacity limited, and the rate and effectiveness of information acquisition
depends strongly on the <strong>structure and ordering</strong> of the study materials.</p>
</blockquote>

<p>They go on to explain progressively differentiated structured learning in
children (animal v plant is learned before rose v daisy).
Even when they give identical solutions, deep linear networks exhibit similar
patterns while shallow ones don’t.
Highlight the importance of studying <em>learning dynamics</em> and representational
evolution during training.</p>

<h2 id="artificial-vs-natural-neural">Artificial vs natural neural</h2>

<p>Comparison problem (ANN vs human): how strong are test subjects’ priors?
Nature v nurture: are faces innate or acquired?</p>

<p>Deep learning asks how neural codes emerge from different learning principles:
traditionally supervised learning, but also suggested others (e.g. Hebbian).</p>

<blockquote>
  <p>a successful AI model that has yet to impact neuroscience proposes instead
that representation formation is driven by the need to accurately predict the
<strong>motivational value of experience</strong>.</p>
</blockquote>

<p>Problems arise due to amounts of labeled data required and credit assignment.
Grand challenge for neurosci: can learning in the brain assign credit across
the neural hierarchy? If so, identify biologically realistic implementation:</p>
<ul>
  <li>one where updates are local, and</li>
  <li>forward and backward network connectivity is not required to be symmetric</li>
</ul>

<p>Hope: ML will soon offer more powerful models in which higher cog functions
emerge naturally via a “blind search” process.
DL has been fused with RL, context-addressable memory, MCTS.
But let’s embrace prev neurosci work: we have understanding of some cog systems,
e.g. the navigation system in the rodent medial temporal lobe, the motor system
in song birds, the saccadic system in the macaque monkey.</p>

<h2 id="catastrophic-interference--resource-allocation-during-learning">Catastrophic interference &amp; resource allocation during learning</h2>

<p>Generally, parameterisation that solves task A is not guaranteed to solve any
other; training on task B, gradient descent drives network weights away from the
local minimum for A.</p>

<p>Evidence grows that offline replay may be important for memory consolidation;
continual learning problem begs the question: is biological learning actively
partitioned so as to avoid catastrophic interference?
They claim “Animals don’t always benefit from interleaved study (e.g.
cello+violin),” but I’m not convinced.</p>

<p>More general: how have biological systems evolved to both minimize negative
transfer (interference) and maximize positive (generalization) between tasks?
Some theories:</p>

<blockquote>
  <p>the brain has found a solution by promoting shared neural codes, which in
turns allows for strong transfer, but deploying control processes to gate out
irrelevant tasks that might provoke interference. They suggest that this
answers the question of why, despite a brain that comprises billions of
neurons and trillions of connections, humans struggle with multi-tasking
problems such typing a line of computer code whilst answering a question.</p>
</blockquote>


        </div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/psi-computational-architecture">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Psi: A Computational Architecture

      </span>
    </a>
  

  
    <a class="page-next" href="/levels-of-bio-plausibility">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Levels of biological plausibility
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>

    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://twitter.com/tkukurin"><i class="fab fa-twitter-square fa-2x" title="Twitter"></i></a><a class="social-icon" href="https://github.com/tkukurin"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/toni/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      

    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>

</html>
